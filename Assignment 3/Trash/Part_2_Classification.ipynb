{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import Process, Lock,Manager\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global quarter\n",
    "global nextQuarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_df(quarter,nextQuarter): \n",
    "    global df1\n",
    "    global df2\n",
    "    col_names_svcg=['loan_sequence_no', 'monthly_reporting_period', 'current_actual_upb', 'current_loan_delinquency_status',\n",
    "                      'loan_age', 'remaning_months_on_legal_maturity', 'repurchase_flag', 'modification_flag', 'zero_bal_code',\n",
    "                      'zero_bal_eff_date', 'current_interest_rate', 'current_deferred_upb', 'ddlpi', 'mi_recoveries', 'net_sales_proceeds',\n",
    "                      'non_mi_recoveries', 'expenses', 'legal_costs', 'maintenance_preservation_cost', 'taxes_insurance', 'misc_expenses',\n",
    "                      'actual_loss_calc', 'modification_cost']\n",
    "    \n",
    "    df1 = pd.read_table(os.path.join('part2_data_downloaded_zips_unzipped/historical_data1_time_'+quarter+\".txt\"), \n",
    "                        delimiter='|', names=col_names_svcg, index_col=None,nrows=200000,usecols=list(np.arange(23)))\n",
    "    df2 = pd.read_table(os.path.join('part2_data_downloaded_zips_unzipped/historical_data1_time_'+nextQuarter+\".txt\"), \n",
    "                        delimiter='|', names=col_names_svcg, index_col=None,nrows=200000, usecols=list(np.arange(23)))\n",
    "\n",
    "\n",
    "# ### Data Preprocessing\n",
    "# Handle Null values\n",
    "# \n",
    "# Change Categorical value type to category (equivalent to factors in R)\n",
    "def remove_nan(dff):\n",
    "    dff.current_loan_delinquency_status = dff.current_loan_delinquency_status.replace('R', '1').astype('float64')\n",
    "    \n",
    "    dff.remaning_months_on_legal_maturity = dff.remaning_months_on_legal_maturity.replace(np.nan, 0)\n",
    "    dff.remaning_months_on_legal_maturity = dff.remaning_months_on_legal_maturity.astype('category')\n",
    "    \n",
    "    dff.repurchase_flag = dff.repurchase_flag.replace(np.nan, 0)\n",
    "    dff.repurchase_flag = dff.repurchase_flag.astype('category')\n",
    "    \n",
    "    dff.modification_flag = dff.modification_flag.replace(np.nan, 0)\n",
    "    dff.modification_flag = dff.modification_flag.astype('category')\n",
    "    \n",
    "    dff.zero_bal_code = dff.zero_bal_code.replace(np.nan, 0)\n",
    "    dff.zero_bal_code = dff.zero_bal_code.astype('category')\n",
    "    \n",
    "    dff.zero_bal_eff_date = dff.zero_bal_eff_date.replace(np.nan, 0)\n",
    "    dff.zero_bal_eff_date = dff.zero_bal_eff_date.astype('category')\n",
    "    \n",
    "    dff.current_deferred_upb = dff.current_deferred_upb.replace(np.nan, 0)\n",
    "    dff.current_deferred_upb = dff.current_deferred_upb.astype('category')\n",
    "    \n",
    "    dff.ddlpi = dff.ddlpi.replace(np.nan, 0)\n",
    "    dff.ddlpi = dff.ddlpi.astype('category')\n",
    "    \n",
    "    dff.mi_recoveries = dff.mi_recoveries.replace(np.nan, 0)\n",
    "    \n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace(np.nan, 0)\n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace('C', 1)\n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace('U', 0)\n",
    "    dff.net_sales_proceeds.astype('float64')\n",
    "    \n",
    "    dff.non_mi_recoveries = dff.non_mi_recoveries.replace(np.nan, 0)\n",
    "    \n",
    "    dff.expenses = dff.expenses.replace(np.nan, 0)\n",
    "    \n",
    "    dff.legal_costs = dff.legal_costs.replace(np.nan, 0)\n",
    "    \n",
    "    dff.maintenance_preservation_cost = dff.maintenance_preservation_cost.replace(np.nan, 0)\n",
    "    dff.taxes_insurance = dff.taxes_insurance.replace(np.nan, 0)\n",
    "    dff.misc_expenses = dff.misc_expenses.replace(np.nan, 0)\n",
    "    dff.actual_loss_calc = dff.actual_loss_calc.replace(np.nan, 0)\n",
    "    dff.modification_cost = dff.modification_cost.replace(np.nan, 0)\n",
    "\n",
    "\n",
    "# #### Processing the data, Change the numerical features to Dummy variables, Create the target variable,  Create Training and Testing datasets\n",
    "def process_data():\n",
    "    ## Create target variable function\n",
    "    def f(row):\n",
    "        if row['current_loan_delinquency_status'] > 0:\n",
    "            val = 1\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "    ## Create dummy variables\n",
    "    df1_dummies = pd.get_dummies(df1[['repurchase_flag', 'modification_flag']])\n",
    "    df2_dummies = pd.get_dummies(df2[['repurchase_flag', 'modification_flag']])\n",
    "\n",
    "    df1_d = df1.drop(['loan_sequence_no','repurchase_flag', 'modification_flag'],axis=1)\n",
    "    df2_d = df2.drop(['loan_sequence_no','repurchase_flag', 'modification_flag'],axis=1)\n",
    "\n",
    "    global df1_final\n",
    "    global df2_final\n",
    "    df1_final = pd.concat([df1_d, df1_dummies], axis=1)\n",
    "    df2_final = pd.concat([df2_d, df2_dummies], axis=1)\n",
    "    \n",
    "    #create target variable \n",
    "    df1_final['Deliquent'] = df1_final.apply(f, axis=1)\n",
    "    df2_final['Deliquent'] = df2_final.apply(f, axis=1)\n",
    "    \n",
    "    ### Create training and testing set\n",
    "    \n",
    "    X_train = df1_final.drop(['current_loan_delinquency_status', 'Deliquent'], axis=1)\n",
    "    y_train = df1_final['Deliquent']\n",
    "\n",
    "    X_test = df2_final.drop(['current_loan_delinquency_status', 'Deliquent'], axis=1)\n",
    "    y_test = df2_final['Deliquent']\n",
    "    \n",
    "    X_train = preprocessing.minmax_scale(X_train) # scale between 0 and 1\n",
    "    X_test = preprocessing.minmax_scale(X_test)\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logred(X_train, y_train,X_test,y_test,return_dict_logred):\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_train_predicted = logreg.predict(X_train)\n",
    "    y_test_predicted = logreg.predict(X_test)\n",
    "\n",
    "    #print(metrics.classification_report(y_train, y_train_predicted))\n",
    "     \n",
    "    conf_mat_logred = metrics.confusion_matrix(y_test, y_test_predicted)\n",
    "    print(conf_mat_logred)\n",
    "\n",
    "    # Compute ROC curve and AUC (Area under the Curve)\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_test_predicted)\n",
    "    \n",
    "    roc_auc_logred = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    return_dict_logred['roc_auc_logred']=roc_auc_logred\n",
    "    return_dict_logred['conf_mat_logred']=conf_mat_logred\n",
    "    \n",
    "    \n",
    "    ## Plot ROC Curve\n",
    "    plt.title(\"Logistic Regression\")\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc_logred)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train, y_train,X_test,y_test,return_dict_rf):\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_train_predicted = rf.predict(X_train)\n",
    "    y_test_predicted = rf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    conf_mat_rf = metrics.confusion_matrix(y_test, y_test_predicted)\n",
    "    print(conf_mat_rf)\n",
    "\n",
    "    # Compute ROC curve and AUC (Area under the Curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_test_predicted)\n",
    "    \n",
    "    roc_auc_rf = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    return_dict_rf['roc_auc_rf']=roc_auc_rf\n",
    "    return_dict_rf['conf_mat_rf']=conf_mat_rf\n",
    "    \n",
    "    ## Plot ROC Curve\n",
    "    plt.title(\"Random Forest\")\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc_rf)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ### Neural Network\n",
    "\n",
    "def nn(X_train, y_train,X_test,y_test,return_dict_nn):\n",
    "\n",
    "    nn = MLPClassifier()\n",
    "\n",
    "    nn.fit(X_train, y_train)\n",
    "\n",
    "    y_train_predicted = nn.predict(X_train)\n",
    "    y_test_predicted = nn.predict(X_test)\n",
    "    \n",
    "    conf_mat_nn = metrics.confusion_matrix(y_test, y_test_predicted)\n",
    "    print(conf_mat_nn)\n",
    "\n",
    "    # Compute ROC curve and AUC (Area under the Curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_test_predicted)\n",
    "    \n",
    "    roc_auc_nn = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    return_dict_nn['roc_auc_nn']=roc_auc_nn\n",
    "    return_dict_nn['conf_mat_nn']=conf_mat_nn\n",
    "    \n",
    "    \n",
    "    ## Plot ROC Curve\n",
    "    plt.title(\"Neural Network\")\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc_nn)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm():\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #y_train_predicted = clf.predict(X_train)\n",
    "    y_test_predicted = clf.predict(X_test)\n",
    "    \n",
    "    global conf_mat_svm\n",
    "    conf_mat_svm=metrics.confusion_matrix(y_test, y_test_predicted)\n",
    "    print(conf_mat_svm)\n",
    "\n",
    "    # Compute ROC curve and AUC (Area under the Curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_test_predicted)\n",
    "    global roc_auc_svm\n",
    "    roc_auc_svm = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    ## Plot ROC Curve\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc_svm)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4924a903632c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendQuarter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartQuarter\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mendQuarter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mquarters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartQuarter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mstartQuarter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_next_quarter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartQuarter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mquarters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendQuarter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def genMatrix(quarter,roc_auc_logred,roc_auc_rf,roc_auc_nn,conf_mat_logred,conf_mat_rf,conf_mat_nn,matrix):\n",
    "    all_auc={'logred':roc_auc_logred,'rf':roc_auc_rf,'nn':roc_auc_nn}\n",
    "    model=max(all_auc.items(),key=operator.itemgetter(1))[0]\n",
    "    all_conf={'logred':conf_mat_logred,'rf':conf_mat_rf,'nn':conf_mat_nn}\n",
    "    all_conf_array = all_conf[model]\n",
    "    No_of_actual_delq = all_conf_array[1][0] + all_conf_array[1][1]\n",
    "    No_of_pred_delq = all_conf_array[0][1] + all_conf_array[1][1]\n",
    "    No_of_records = all_conf_array[0][1] + all_conf_array[1][1] + all_conf_array[1][0] + all_conf_array[0][0]\n",
    "    No_of_delq_properly_classified = all_conf_array[1][1]\n",
    "    No_of_nonDelq_improperly_classified_as_delq = all_conf_array[0][1]\n",
    "    \n",
    "    # In[131]:\n",
    "    \n",
    "    all_conf_df = pd.DataFrame(OrderedDict((('Quarter',[quarter]), \n",
    "                                 ('No_of_actual_delq',[No_of_actual_delq]),\n",
    "                                 ('No_of_pred_delq',[No_of_pred_delq]),\n",
    "                                 ('No_of_records',[No_of_records]),\n",
    "                                 ('No_of_delq_properly_classified',[No_of_delq_properly_classified]),\n",
    "                                 ('No_of_nonDelq_improperly_classified_as_delq',[No_of_nonDelq_improperly_classified_as_delq]))))\n",
    "    \n",
    "    matrix=pd.concat([all_conf_df, matrix],axis=0)\n",
    "    return matrix\n",
    "    \n",
    "def get_next_quarter(QUARTER):\n",
    "        QUARTER='Q12005'\n",
    "        quarterNumber =  int(QUARTER[1])\n",
    "        quarterYear= int(QUARTER[2:6])\n",
    "        \n",
    "        if quarterNumber < 4:\n",
    "            newQuarterNumber = quarterNumber + 1\n",
    "            newQuarterYear = quarterYear\n",
    "        else:\n",
    "            newQuarterNumber = quarterNumber - 3\n",
    "            newQuarterYear = quarterYear + 1\n",
    "            \n",
    "        QUARTER2 = \"Q\" + str(newQuarterNumber) + str(newQuarterYear)\n",
    "            \n",
    "        return QUARTER2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global X_train \n",
    "    global y_train\n",
    "    global X_test\n",
    "    global y_test\n",
    "    global matrix\n",
    "    global conf_mat_logred\n",
    "    global conf_mat_rf\n",
    "    global conf_mat_nn\n",
    "    global roc_auc_logred\n",
    "    global roc_auc_rf\n",
    "    global roc_auc_nn\n",
    "    manager=Manager()\n",
    "    return_dict_logred=manager.dict()\n",
    "    return_dict_rf=manager.dict()\n",
    "    return_dict_nn=manager.dict()\n",
    "    matrix = pd.DataFrame(OrderedDict((('Quarter',[]), \n",
    "                                     ('No_of_actual_delq',[]),\n",
    "                                     ('No_of_pred_delq',[]),\n",
    "                                     ('No_of_records',[]),\n",
    "                                     ('No_of_delq_properly_classified',[]),\n",
    "                                     ('No_of_nonDelq_improperly_classified_as_delq',[]))))\n",
    "    \n",
    "    arg_len=len(sys.argv)\n",
    "    quarters=[]\n",
    "    end=''\n",
    "    if arg_len == 3:\n",
    "        startQuarter=sys.argv[1]\n",
    "        endQuarter=sys.argv[2]\n",
    "        end=endQuarter\n",
    "        while(startQuarter != endQuarter):\n",
    "            quarters.append(startQuarter)\n",
    "            startQuarter=get_next_quarter(startQuarter)\n",
    "        quarters.append(endQuarter)\n",
    "    elif arg_len == 2:\n",
    "        startQuarter=sys.argv[1]\n",
    "        quarters.append(startQuarter)\n",
    "        end=startQuarter\n",
    "    else:\n",
    "        print(\"running for default Q12005\")\n",
    "        quarter = 'Q12005'\n",
    "        quarters.append(quarter)\n",
    "        end=quarter\n",
    "    #download\n",
    "    downloadQuarters=quarters[:]\n",
    "    downloadQuarters.append(get_next_quarter(end))\n",
    "    get_data(downloadQuarters)\n",
    "    \n",
    "    \n",
    "    for q in quarters:\n",
    "        nextQuarter=get_next_quarter(q)\n",
    "        load_data_df(q,nextQuarter)\n",
    "        remove_nan(df1)\n",
    "        remove_nan(df2)\n",
    "        X_train,y_train,X_test,y_test=process_data()\n",
    "        print(\"process data executed\")\n",
    "        \n",
    "        p1 = Process(target=logred,args=(X_train, y_train,X_test,y_test,return_dict_logred))\n",
    "        p2 = Process(target=rf,args=(X_train, y_train,X_test,y_test,return_dict_rf))\n",
    "        p3 = Process(target=nn,args=(X_train, y_train,X_test,y_test,return_dict_nn))\n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p3.start()\n",
    "        p1.join()\n",
    "        p2.join()\n",
    "        p3.join()\n",
    "        matrix=genMatrix(q,return_dict_logred['roc_auc_logred'],return_dict_rf['roc_auc_rf'],return_dict_nn['roc_auc_nn'],return_dict_logred['conf_mat_logred'],return_dict_rf['conf_mat_rf'],return_dict_nn['conf_mat_nn'],matrix)\n",
    "        \n",
    "    print(matrix)\n",
    "    matrix.to_csv('matrix_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
